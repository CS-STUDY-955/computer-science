# ChatGPT(Generative Pre-trained Transformer)
- OpenAI에서 2022년 11월 출시한 챗봇
- 의학 학술지에 실린 논문 요약 : 표절검사 100% 통과
- 로스쿨시험, 의사 면허 시험 등 합격

## 원리
- Supervised Learning(지도학습), Reinforcement Learning(강화학습) 사용(ex 알파고)
### 지도학습
- 기존의 데이터를 통해 학습하도록 설계
- 인공지능 개발자는 데이터에 대한 정답(label)을 알고 있음
- 추천엔진, 이미지인식, 목적지 도착 시간 계산 등 활용
### 강화학습
- 학습하는 시스템(Agent)가 환경을 관찰하고 행동하여 그 결과를 통해 보상을 획득
- 보상이 축적되어 판단을 강화 > 판단에 따라 행동
- 개발자는 agent가 더 많은 보상을 획득할 수 있도록 정책 구현
- 알파고, 자율주행, 게임 등
### 기존 AI의 단점
- 유용성 부족 : 질문과 전혀 상관없는 내용
- 학습에 많은 양의 데이터 필요
- 잘못된 데이터가 입력되면 결과에 영향을 줌
### ChatGPT의 극복 방법
- RLHF(Reinforcement Learning from Human Feedback)
- 1단계 : 데이터 전체 중 검열된 질 좋은 데이터만 학습
    - 1단계 만으로는 여전히 유용성이 부족할 수 있음
- 2단계 : 1단계 학습을 통해 얻어낸 모델에 사람이 직접 지도학습
    - 언어모델의 수행결과를 여러개 추출하여 사람이 답변의 우선순위 점수 부여 > 데이터 학습 성능 향상
    - 현재 ChatGPT 에 사용되는 기준은 1750억개
    - 지속적으로 교육 반복 : 강화학습
- 3단계 : 과거 데이터 학습이 아닌 실제 언어를 작동하면서 생기는 문제를 미세 조정 > 성능이 크게 변화하지는 않음
    - 성능 개선 분석 가능
    - 유용성 평가, 진실성 평가, 무해성 평가
- 1~3단계 무한 반복

## 기존 서비스와의 차이점
| 구글 | ChatGPT |
| --- | --- |
| 검색된 문장을 단어로 쪼개 검색 | 대화형 서비스 |
| 키워드가 포함된 문서의 주소 제공 | 기존에 학습된 데이터와 대화를 통해 얻은 키워드를 바탕으로 답변을 제시 |
| 사용자가 사이트 방문하여 키워드 확인 | 기존에 없는 데이터의 경우 예측을 통해 답변 제시 |
| 이해

## 단점
- 일상 대화는 힘듦
- 논리, 상식에 취약함
- 사람 의존도가 높기 때문에 데이터 편향성 존재할 수 있음.
    - 특정 사람이 편향된 시선으로만 학습시킬 수 있음
- 확률기반이기 때문에 100%정확한 데이터를 제공하지 않음 <br>
<img decoding="async" src="https://user-images.githubusercontent.com/84913626/216805868-f4e492c1-d2a5-4f36-a8b7-df88b57984e2.png" alt="" height=300 >
- 현재 2021년까지의 데이터로 학습되어 있기 때문에 학습되지 않은 데이터에 대해서는 잘못된 정보를 줄 수 있음(실시간 x)
- 사람이 많이 투여되기 때문에 비용 

## 참고자료
- https://www.youtube.com/watch?v=oIoMNsFDE6k
- https://www.chosun.com/economy/tech_it/2023/02/06/P2ZEF55AGVAYDLWSKBXTNMRAOM/
